{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0082b516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules loaded\n"
     ]
    }
   ],
   "source": [
    "# import system libs\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "# import data handling tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import plotly.express as px\n",
    "\n",
    "# import Deep learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input, Average, Dense, Concatenate\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print ('modules loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70654b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data paths with labels\n",
    "def define_paths(data_dir):\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "\n",
    "    folders = os.listdir(data_dir)\n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(data_dir, folder)\n",
    "        files = os.listdir(folder_path)\n",
    "        for file in files:\n",
    "            fpath = os.path.join(folder_path, file)\n",
    "            filepaths.append(fpath)\n",
    "            labels.append(folder)\n",
    "\n",
    "    return filepaths, labels\n",
    "\n",
    "\n",
    "# Concatenate data paths with labels into one dataframe ( to later be fitted into the model )\n",
    "def define_df(files, classes):\n",
    "    Fseries = pd.Series(files, name= 'filepaths')\n",
    "    Lseries = pd.Series(classes, name='labels')\n",
    "    return pd.concat([Fseries, Lseries], axis= 1)\n",
    "\n",
    "# Split dataframe to train, valid, and test\n",
    "def split_data(data_dir):\n",
    "    # train dataframe\n",
    "    files, classes = define_paths(data_dir)\n",
    "    df = define_df(files, classes)\n",
    "    strat = df['labels']\n",
    "    train_df, dummy_df = train_test_split(df,  train_size= 0.8, shuffle= True, random_state= 123, stratify= strat)\n",
    "\n",
    "    # valid and test dataframe\n",
    "    strat = dummy_df['labels']\n",
    "    valid_df, test_df = train_test_split(dummy_df,  train_size= 0.5, shuffle= True, random_state= 123, stratify= strat)\n",
    "\n",
    "    return train_df, valid_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e134457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gens (train_df, valid_df, test_df, batch_size):\n",
    "    '''\n",
    "    This function takes train, validation, and test dataframe and fit them into image data generator, because model takes data from image data generator.\n",
    "    Image data generator converts images into tensors. '''\n",
    "\n",
    "\n",
    "    # define model parameters\n",
    "    img_size = (224, 224)\n",
    "    channels = 3 # either BGR or Grayscale\n",
    "    color = 'rgb'\n",
    "    img_shape = (img_size[0], img_size[1], channels)\n",
    "\n",
    "    datagen = ImageDataGenerator(preprocessing_function= None)\n",
    "\n",
    "    train_gen = datagen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
    "                                        color_mode= color, shuffle= True, batch_size= batch_size)\n",
    "\n",
    "    valid_gen = datagen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
    "                                        color_mode= color, shuffle= True, batch_size= batch_size)\n",
    "\n",
    "    test_gen = datagen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
    "                                        color_mode= color, shuffle= False, batch_size= batch_size)\n",
    "\n",
    "    return train_gen, valid_gen, test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cceb566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16000 validated image filenames belonging to 10 classes.\n",
      "Found 2000 validated image filenames belonging to 10 classes.\n",
      "Found 2000 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "data_dir = './Pill Dataset'\n",
    "\n",
    "try:\n",
    "    # Get splitted data\n",
    "    train_df, valid_df, test_df = split_data(data_dir)\n",
    "\n",
    "    # Get Generators\n",
    "    batch_size = 40\n",
    "    train_gen, valid_gen, test_gen = create_gens(train_df, valid_df, test_df, batch_size)\n",
    "\n",
    "except:\n",
    "    print('Invalid Input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9b052fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved base models\n",
    "base_model1 = load_model(\"ResNet50_93.15.h5\")\n",
    "base_model2 = load_model(\"InceptionV3_96.15.h5\")\n",
    "base_model3 = load_model(\"MobileNet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de4a6230",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model1 = Model(inputs=base_model1.inputs,\n",
    "                outputs=base_model1.outputs,\n",
    "                name='ResNet50')\n",
    "\n",
    "base_model2 = Model(inputs=base_model2.inputs,\n",
    "                outputs=base_model2.outputs,\n",
    "                name='InceptionV3')\n",
    "\n",
    "base_model3 = Model(inputs=base_model3.inputs,\n",
    "                outputs=base_model3.outputs,\n",
    "                name='MobileNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7129f4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 1214s 3s/step\n",
      "400/400 [==============================] - 690s 2s/step\n",
      "400/400 [==============================] - 279s 697ms/step\n",
      "Training duration: 2192.993932723999 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create AdaBoost classifiers with Decision Trees as weak learners\n",
    "base_models = [base_model1, base_model2, base_model3]\n",
    "adaboost_classifiers = []\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "for base_model in base_models:\n",
    "    base_model_name = base_model.name\n",
    "    base_model_features = base_model.predict(train_gen, verbose=1)\n",
    "    adaboost_classifier = AdaBoostClassifier(\n",
    "        base_estimator=DecisionTreeClassifier(max_depth=2),\n",
    "        n_estimators=50,  # You can adjust the number of estimators\n",
    "        learning_rate=1.0,\n",
    "        random_state=42\n",
    "    )\n",
    "    adaboost_classifier.fit(base_model_features, train_gen.classes)\n",
    "    adaboost_classifiers.append((base_model_name, adaboost_classifier))\n",
    "    \n",
    "# Record end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training duration\n",
    "training_duration = end_time - start_time\n",
    "print(f\"Training duration: {training_duration} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "169f20a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 129s 3s/step\n",
      "50/50 [==============================] - 82s 2s/step\n",
      "50/50 [==============================] - 33s 666ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'ResNet50' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m validation_features \u001b[38;5;241m=\u001b[39m [base_model\u001b[38;5;241m.\u001b[39mpredict(test_gen, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m base_model \u001b[38;5;129;01min\u001b[39;00m base_models]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, adaboost_classifier \u001b[38;5;129;01min\u001b[39;00m adaboost_classifiers:\n\u001b[1;32m----> 5\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m adaboost_classifier\u001b[38;5;241m.\u001b[39mscore(validation_features[\u001b[43mbase_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m], test_gen\u001b[38;5;241m.\u001b[39mclasses)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: 'ResNet50' is not in list"
     ]
    }
   ],
   "source": [
    "# Evaluate the AdaBoost ensemble on the validation set\n",
    "validation_features = [base_model.predict(test_gen, verbose=1) for base_model in base_models]\n",
    "\n",
    "for model_name, adaboost_classifier in adaboost_classifiers:\n",
    "    accuracy = adaboost_classifier.score(validation_features[base_models.index(model_name)], test_gen.classes)\n",
    "    print(f\"Accuracy of {model_name}: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02684b8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbase_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "print(base_models.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9885f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays to store individual model predictions\n",
    "individual_predictions = []\n",
    "\n",
    "# Get predictions from each model in the ensemble\n",
    "for model_name, adaboost_classifier in adaboost_classifiers:\n",
    "    predictions = adaboost_classifier.predict(validation_features[base_models.index(model_name)])\n",
    "    individual_predictions.append(predictions)\n",
    "\n",
    "# Combine predictions using majority voting\n",
    "ensemble_predictions = np.sum(individual_predictions, axis=0)\n",
    "final_predictions = np.argmax(ensemble_predictions, axis=1)\n",
    "\n",
    "# You can evaluate the accuracy of the ensemble's predictions\n",
    "correct_predictions = (final_predictions == valid_generator.classes)\n",
    "accuracy = np.mean(correct_predictions)\n",
    "print(f\"Ensemble Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd5a330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(hist):\n",
    "    '''\n",
    "    This function take training model and plot history of accuracy and losses with the best epoch in both of them.\n",
    "    '''\n",
    "\n",
    "    # Define needed variables\n",
    "    tr_acc = hist.history['accuracy']\n",
    "    tr_loss = hist.history['loss']\n",
    "    val_acc = hist.history['val_accuracy']\n",
    "    val_loss = hist.history['val_loss']\n",
    "    index_loss = np.argmin(val_loss)\n",
    "    val_lowest = val_loss[index_loss]\n",
    "    index_acc = np.argmax(val_acc)\n",
    "    acc_highest = val_acc[index_acc]\n",
    "    Epochs = [i+1 for i in range(len(tr_acc))]\n",
    "    loss_label = f'best epoch= {str(index_loss + 1)}'\n",
    "    acc_label = f'best epoch= {str(index_acc + 1)}'\n",
    "\n",
    "    # Plot training history\n",
    "    plt.figure(figsize= (20, 8))\n",
    "    plt.style.use('fivethirtyeight')\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
    "    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
    "    plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
    "    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
    "    plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout\n",
    "    plt.show()\n",
    "    \n",
    "plot_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c546d68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval = ensemble_model.evaluate(train_gen, verbose= 1)\n",
    "valid_eval = ensemble_model.evaluate(valid_gen, verbose= 1)\n",
    "test_eval = ensemble_model.evaluate(test_gen, verbose= 1)\n",
    "\n",
    "print(\"Train Loss: \", train_eval[0])\n",
    "print(\"Train Accuracy: \", train_eval[1])\n",
    "print('-' * 20)\n",
    "print(\"Validation Loss: \", valid_eval[0])\n",
    "print(\"Validation Accuracy: \", valid_eval[1])\n",
    "print('-' * 20)\n",
    "print(\"Test Loss: \", test_eval[0])\n",
    "print(\"Test Accuracy: \", test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef904963",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ensemble_model.predict_generator(test_gen)\n",
    "y_pred_class = np.argmax(preds, axis=1)\n",
    "print(y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0828da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_gen.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b0227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision\n",
    "precision = precision_score(test_gen.classes, y_pred_class, average = 'weighted')\n",
    "print(f\"Precision Score = {precision}\")\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(test_gen.classes, y_pred_class, average = 'weighted')\n",
    "print(f\"Recall Score = {recall}\")\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(test_gen.classes, y_pred_class, average = 'weighted')\n",
    "print(f\"F1 Score = {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c00bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = test_gen.class_indices\n",
    "classes = list(class_dict.keys())\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(test_gen.classes, y_pred_class)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=test_gen.class_indices.keys(),\n",
    "            yticklabels=test_gen.class_indices.keys())\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix - Stacking Ensemble')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(test_gen.classes, y_pred_class, target_names= classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e06fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble_model.save(\"Ensemble_Model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
