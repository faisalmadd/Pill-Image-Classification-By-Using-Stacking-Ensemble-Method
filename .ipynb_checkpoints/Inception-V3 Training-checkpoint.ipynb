{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0576521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules loaded\n"
     ]
    }
   ],
   "source": [
    "# import system libs\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import pathlib\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "# import data handling tools\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import plotly.express as px\n",
    "\n",
    "# import Deep learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print ('modules loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83b89550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data paths with labels\n",
    "def define_paths(data_dir):\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "\n",
    "    folds = os.listdir(data_dir)\n",
    "    for fold in folds:\n",
    "        foldpath = os.path.join(data_dir, fold)\n",
    "        filelist = os.listdir(foldpath)\n",
    "        for file in filelist:\n",
    "            fpath = os.path.join(foldpath, file)\n",
    "            filepaths.append(fpath)\n",
    "            labels.append(fold)\n",
    "\n",
    "    return filepaths, labels\n",
    "\n",
    "\n",
    "# Concatenate data paths with labels into one dataframe ( to later be fitted into the model )\n",
    "def define_df(files, classes):\n",
    "    Fseries = pd.Series(files, name= 'filepaths')\n",
    "    Lseries = pd.Series(classes, name='labels')\n",
    "    return pd.concat([Fseries, Lseries], axis= 1)\n",
    "\n",
    "# Split dataframe to train, valid, and test\n",
    "def split_data(data_dir):\n",
    "    # train dataframe\n",
    "    files, classes = define_paths(data_dir)\n",
    "    df = define_df(files, classes)\n",
    "    strat = df['labels']\n",
    "    train_df, dummy_df = train_test_split(df,  train_size= 0.8, shuffle= True, random_state= 123, stratify= strat)\n",
    "\n",
    "    # valid and test dataframe\n",
    "    strat = dummy_df['labels']\n",
    "    valid_df, test_df = train_test_split(dummy_df,  train_size= 0.5, shuffle= True, random_state= 123, stratify= strat)\n",
    "\n",
    "    return train_df, valid_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f911bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gens(train_df, valid_df, test_df, batch_size):\n",
    "    img_size = (224, 224)\n",
    "    channels = 3\n",
    "    color = 'rgb'\n",
    "    img_shape = (img_size[0], img_size[1], channels)\n",
    "\n",
    "    tr_gen = ImageDataGenerator()\n",
    "    ts_gen = ImageDataGenerator()\n",
    "\n",
    "    train_gen = tr_gen.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels', target_size=img_size,\n",
    "                                           class_mode='categorical', color_mode=color, shuffle=True,\n",
    "                                           batch_size=batch_size)\n",
    "\n",
    "    valid_gen = ts_gen.flow_from_dataframe(valid_df, x_col='filepaths', y_col='labels', target_size=img_size,\n",
    "                                           class_mode='categorical', color_mode=color, shuffle=True,\n",
    "                                           batch_size=batch_size)\n",
    "\n",
    "    test_gen = ts_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col='labels', target_size=img_size,\n",
    "                                          class_mode='categorical', color_mode=color, shuffle=False,\n",
    "                                          batch_size=batch_size)\n",
    "\n",
    "    return train_gen, valid_gen, test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06c78ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(gen):\n",
    "    '''\n",
    "    This function take the data generator and show sample of the images\n",
    "    '''\n",
    "\n",
    "    # return classes , images to be displayed\n",
    "    g_dict = gen.class_indices        # defines dictionary {'class': index}\n",
    "    classes = list(g_dict.keys())     # defines list of dictionary's kays (classes), classes names : string\n",
    "    images, labels = next(gen)        # get a batch size samples from the generator\n",
    "\n",
    "    # calculate number of displayed samples\n",
    "    length = len(labels)        # length of batch size\n",
    "    sample = min(length, 25)    # check if sample less than 25 images\n",
    "\n",
    "    plt.figure(figsize= (20, 20))\n",
    "\n",
    "    for i in range(sample):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        image = images[i] / 255       # scales data to range (0 - 255)\n",
    "        plt.imshow(image)\n",
    "        index = np.argmax(labels[i])  # get image index\n",
    "        class_name = classes[index]   # get class of image\n",
    "        plt.title(class_name, color= 'blue', fontsize= 12)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b751ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(hist):\n",
    "    '''\n",
    "    This function take training model and plot history of accuracy and losses with the best epoch in both of them.\n",
    "    '''\n",
    "\n",
    "    # Define needed variables\n",
    "    tr_acc = hist.history['accuracy']\n",
    "    tr_loss = hist.history['loss']\n",
    "    val_acc = hist.history['val_accuracy']\n",
    "    val_loss = hist.history['val_loss']\n",
    "    index_loss = np.argmin(val_loss)\n",
    "    val_lowest = val_loss[index_loss]\n",
    "    index_acc = np.argmax(val_acc)\n",
    "    acc_highest = val_acc[index_acc]\n",
    "    Epochs = [i+1 for i in range(len(tr_acc))]\n",
    "    loss_label = f'best epoch= {str(index_loss + 1)}'\n",
    "    acc_label = f'best epoch= {str(index_acc + 1)}'\n",
    "\n",
    "    # Plot training history\n",
    "    plt.figure(figsize= (20, 8))\n",
    "    plt.style.use('fivethirtyeight')\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
    "    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
    "    plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
    "    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
    "    plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a83c1124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize= False, title= 'Confusion Matrix', cmap= plt.cm.Blues):\n",
    "    '''\n",
    "    This function plot confusion matrix method from sklearn package.\n",
    "    '''\n",
    "\n",
    "    plt.figure(figsize= (10, 10))\n",
    "    plt.imshow(cm, interpolation= 'nearest', cmap= cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation= 45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis= 1)[:, np.newaxis]\n",
    "        print('Normalized Confusion Matrix')\n",
    "\n",
    "    else:\n",
    "        print('Confusion Matrix, Without Normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):    \n",
    "        plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827b6e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16000 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "data_dir = './Pill Dataset'\n",
    "\n",
    "try:\n",
    "    # Get splitted data\n",
    "    train_df, valid_df, test_df = split_data(data_dir)\n",
    "\n",
    "    # Get Generators\n",
    "    batch_size = 40\n",
    "    train_gen, valid_gen, test_gen = create_gens(train_df, valid_df, test_df, batch_size)\n",
    "\n",
    "except:\n",
    "    print('Invalid Input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae955e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = os.listdir(data_dir)\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0add626",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_distribution = [len(os.listdir(data_dir + \"/\" + name)) for name in class_names]\n",
    "class_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2feb29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.pie(\n",
    "    names=class_names,\n",
    "    values=class_distribution,\n",
    "    width=500,\n",
    "    hole=0.2,\n",
    "    title=\"Class Distribution\"\n",
    ")\n",
    "fig.update_layout({'title':{'x':0.5}})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845665b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93637794",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (224, 224)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "class_count = len(list(train_gen.class_indices.keys())) # to define the number of classes in the dense layer\n",
    "\n",
    "# create pre-trained model (you can build on a pretrained model such as EfficientNet, VGG, or ResNet)\n",
    "base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
    "    include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max')\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001),\n",
    "    Dense(256, kernel_regularizer=regularizers.l2(l=0.016),\n",
    "          activity_regularizer=regularizers.l1(0.006),\n",
    "          bias_regularizer=regularizers.l1(0.006), activation='relu'),\n",
    "    Dropout(rate=0.45, seed=123),\n",
    "    Dense(class_count, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4500d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 40  # set batch size for training\n",
    "epochs = 10  # number of all epochs in training\n",
    "\n",
    "# Define ReduceLROnPlateau callback\n",
    "lr_callback = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, verbose=1, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "history = model.fit(x=train_gen, epochs=epochs, batch_size=batch_size,\n",
    "                    validation_data=valid_gen, shuffle=True,\n",
    "                    callbacks=[lr_callback])\n",
    "\n",
    "# Record end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training duration\n",
    "training_duration = end_time - start_time\n",
    "print(f\"Training duration: {training_duration} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f890fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e8bc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_length = len(test_df)\n",
    "test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
    "test_steps = ts_length // test_batch_size\n",
    "\n",
    "train_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n",
    "valid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n",
    "test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n",
    "\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Validation Loss: \", valid_score[0])\n",
    "print(\"Validation Accuracy: \", valid_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ac151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_generator(test_gen)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7c692",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_dict = test_gen.class_indices\n",
    "classes = list(g_dict.keys())\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_gen.classes, y_pred)\n",
    "plot_confusion_matrix(cm= cm, classes= classes, title = 'Confusion Matrix')\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(test_gen.classes, y_pred, target_names= classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
